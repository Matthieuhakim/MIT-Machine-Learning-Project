{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a3eedc50",
   "metadata": {},
   "source": [
    "# Point Prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "a30e31cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "using CSV, DataFrames, Plots, Random, Statistics, LinearAlgebra, JuMP, Gurobi, StatsBase, Dates\n",
    "using Flux: onehotbatch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "673849f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load datasets\n",
    "daily_sales = CSV.read(\"modelling data/daily_sales.csv\", DataFrame)\n",
    "daily_sales_ingredients_predictions = CSV.read(\"modelling data/daily_sales_ingredients_predictions.csv\", DataFrame)\n",
    "daily_sales_ingredients_actuals = CSV.read(\"modelling data/daily_sales_ingredients_actuals.csv\", DataFrame)\n",
    "daily_sales_actuals = CSV.read(\"modelling data/daily_sales_actuals.csv\", DataFrame)\n",
    "ingredient_prices = CSV.read(\"modelling data/ingredient_prices.csv\", DataFrame)\n",
    "pizza_ingredient_matrix = CSV.read(\"modelling data/pizza_ingredient_matrix.csv\", DataFrame)\n",
    "pizzas = CSV.read(\"modelling data/pizzas.csv\", DataFrame)\n",
    "\n",
    "# Convert DataFrames to matrices if needed\n",
    "daily_sales_mat = Matrix(daily_sales[:, Not(:date)])   # remove 'date' column\n",
    "ingredient_prices_mat = Matrix(ingredient_prices[:, Not(:ingredient)]) # keep only prices\n",
    "pizza_ingredient_matrix_mat = Matrix(pizza_ingredient_matrix[:, Not([:pizza_type_id, :pizza_name, :category])])\n",
    "pizzas_mat = Matrix(pizzas[:, Not([:pizza_id, :pizza_type_id, :size])]) # only prices\n",
    "\n",
    "# Get original column names\n",
    "orig_cols = names(daily_sales_ingredients_predictions)\n",
    "\n",
    "# Create cleaned names by removing the prefix where it appears\n",
    "clean_cols = Symbol.(replace.(String.(orig_cols), \"ingredient_\" => \"\"))\n",
    "\n",
    "# Apply new names back to the DataFrame\n",
    "rename!(daily_sales_ingredients_predictions, Dict(orig_cols .=> clean_cols))\n",
    "rename!(daily_sales_ingredients_actuals, Dict(orig_cols .=> clean_cols));"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "4ffed62d",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = DataFrame(CSV.File(\"modelling data/daily_sales_ingredients.csv\"))\n",
    "\n",
    "# Split train/test 80/20 in order to avoid data leakage\n",
    "n = nrow(df)\n",
    "n_train = round(Int, 0.8 * n)\n",
    "\n",
    "train_df = df[1:n_train, :]\n",
    "test_df  = df[(n_train+1):end, :]\n",
    "\n",
    "# if column starts with ingredient_ , set as as target\n",
    "feature_cols = filter(col -> !startswith(col, \"ingredient_\"), names(df))\n",
    "target_cols = filter(col -> startswith(col, \"ingredient_\"), names(df))\n",
    "\n",
    "X_train = Matrix(train_df[:, feature_cols])\n",
    "X_test  = Matrix(test_df[:, feature_cols])\n",
    "\n",
    "y_train = Matrix(train_df[:, target_cols])\n",
    "y_test  = Matrix(test_df[:, target_cols])\n",
    ";"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "08621f90",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Sets ---\n",
    "P = pizzas.pizza_id                     # pizza SKUs\n",
    "I = ingredient_prices.ingredient        # ingredients\n",
    "\n",
    "# --- Parameters ---\n",
    "\n",
    "# Pizza demand (single day forecast)\n",
    "d = Dict(p => daily_sales_actuals[!, p][1] for p in P)\n",
    "\n",
    "# Pizza sale price\n",
    "π = Dict(p => pizzas[!, :price][findfirst(==(p), pizzas[!, :pizza_id])] for p in P)\n",
    "\n",
    "# Predicted ingredient availability (x_i is FIXED, not a decision variable)\n",
    "x_pred = Dict(i => daily_sales_ingredients_predictions[!, i][1] for i in I)\n",
    "\n",
    "# Ingredient usage per pizza (kg): r[p, i]\n",
    "r = Dict()\n",
    "for p in P\n",
    "    pizza_idx = findfirst(==(p), pizzas[!, :pizza_id])\n",
    "    pizza_type_id = pizzas[!, :pizza_type_id][pizza_idx]\n",
    "\n",
    "    for i in I\n",
    "        row_idx = findfirst(==(pizza_type_id), pizza_ingredient_matrix[!, :pizza_type_id])\n",
    "        r[(p,i)] = pizza_ingredient_matrix[row_idx, i]\n",
    "    end\n",
    "end\n",
    "\n",
    "# Initial ingredient inventory\n",
    "I0 = Dict(i => 0.0 for i in I)\n",
    "\n",
    "# Penalty for unmet pizza demand\n",
    "α = Dict(p => 10.0 for p in P)\n",
    "\n",
    "# Spoilage cost per kg of leftover ingredient\n",
    "s = Dict(i => 0.1 * ingredient_prices[!, :price_per_kg][findfirst(==(i), ingredient_prices[!, :ingredient])] \n",
    "            for i in I)\n",
    "\n",
    "# Storage capacity\n",
    "C = 200.0\n",
    ";\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "06004566",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original train size: (859, 549) -> Expanded train size: (56694, 615)\n",
      "Original test size: (215, 549) -> Expanded test size: (14190, 615)\n"
     ]
    }
   ],
   "source": [
    "n_targets = length(target_cols)\n",
    "\n",
    "# Function to expand dataset\n",
    "function expand_dataset(X::Matrix, Y::Matrix)\n",
    "    n_samples, n_features = size(X)\n",
    "    _, n_targets = size(Y)\n",
    "\n",
    "    # Prepare storage\n",
    "    long_X = Float64[]\n",
    "    long_y = Float64[]\n",
    "    long_target_index = Int[]\n",
    "\n",
    "    # Expand\n",
    "    for i in 1:n_samples\n",
    "        for j in 1:n_targets\n",
    "            append!(long_X, vec(X[i, :]))     # feature columns\n",
    "            push!(long_y, Y[i, j])            # target value\n",
    "            push!(long_target_index, j)       # ingredient index\n",
    "        end\n",
    "    end\n",
    "\n",
    "    # Reshape features\n",
    "    long_X = reshape(long_X, n_features, n_samples*n_targets)'  # (rows, features)\n",
    "\n",
    "    # One-hot encode target ingredient\n",
    "    target_onehot_matrix = Array(onehotbatch(long_target_index, 1:n_targets))'  # (rows, n_targets)\n",
    "\n",
    "    # Combine original features + one-hot\n",
    "    X_long = hcat(long_X, target_onehot_matrix)\n",
    "    y_long = long_y\n",
    "\n",
    "    return X_long, y_long\n",
    "end\n",
    "\n",
    "# Expand train and test sets\n",
    "X_train_long, y_train_long = expand_dataset(X_train, y_train)\n",
    "X_test_long, y_test_long   = expand_dataset(X_test, y_test)\n",
    "\n",
    "println(\"Original train size: \", size(X_train), \" -> Expanded train size: \", size(X_train_long))\n",
    "println(\"Original test size: \", size(X_test), \" -> Expanded test size: \", size(X_test_long))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "218c2963",
   "metadata": {},
   "outputs": [],
   "source": [
    "grid = IAI.GridSearch(\n",
    "    IAI.OptimalTreeRegressor(random_seed=123, max_categoric_levels_before_warning=50),\n",
    "    max_depth=1:5,\n",
    "    minbucket=1:10\n",
    ")\n",
    "\n",
    "\n",
    "IAI.fit!(grid, X_train_long, y_train_long)\n",
    "best_model = IAI.get_learner(grid)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89362b2e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Predict on test\n",
    "y_pred_long = IAI.predict(best_model, X_test_long)\n",
    "y_pred_long = ceil.(y_pred_long)  # ceil to buy extra ingredient quantities\n",
    "\n",
    "# Reshape predictions to original shape (n_samples, n_targets)\n",
    "n_test_samples = size(X_test, 1)\n",
    "y_pred_matrix = reshape(y_pred_long, n_targets, n_test_samples)'  # (rows=samples, cols=targets)\n",
    "\n",
    "# Save predictions to CSV\n",
    "pred_df = DataFrame(y_pred_matrix, Symbol.(target_cols))\n",
    "CSV.write(\"point_predictions.csv\", pred_df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04ab88ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Leaf indices for train and test sets\n",
    "leaf_train = IAI.apply(best_model, X_train_long)\n",
    "leaf_test = IAI.apply(best_model, X_test_long)\n",
    "\n",
    "# Similarity sets: for each test row (day), store indices of train rows in the same leaf\n",
    "# Convert expanded indices back to original day indices\n",
    "S = Dict{Int, Vector{Int}}()\n",
    "n_train_samples = size(X_train, 1)\n",
    "\n",
    "for t in 1:size(X_test, 1)\n",
    "    # Find all expanded training rows in the same leaf as test day t\n",
    "    expanded_indices = findall(leaf_train .== leaf_test[t])\n",
    "    \n",
    "    # Convert expanded indices to original day indices\n",
    "    # Each original day is expanded into n_targets rows\n",
    "    # Expanded index idx -> Original day = (idx - 1) ÷ n_targets + 1\n",
    "    original_day_indices = unique([(idx - 1) ÷ n_targets + 1 for idx in expanded_indices])\n",
    "    \n",
    "    S[t] = original_day_indices\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec9b2ff9",
   "metadata": {},
   "outputs": [],
   "source": [
    "function run_strategy_weighted(daily_sales_actuals, df_train; S, weight=true)\n",
    "    total_days = size(daily_sales_actuals, 1)\n",
    "\n",
    "    metrics = DataFrame(\n",
    "        day = 1:total_days,\n",
    "        pizza_produced = zeros(total_days),\n",
    "        unmet_pizza_demand = zeros(total_days),\n",
    "        leftover_ingredients = zeros(total_days),\n",
    "        daily_profit = zeros(total_days)\n",
    "    )\n",
    "\n",
    "    total_profit = 0.0\n",
    "    I0_current = Dict(i => 0.0 for i in I)\n",
    "\n",
    "    for t in 1:total_days\n",
    "        # --- Demand for pizzas today ---\n",
    "        d_day = Dict(p => daily_sales_actuals[!, p][t] for p in P)\n",
    "\n",
    "        # --- Weighted ingredient requirements ---\n",
    "        req_i = Dict{eltype(I), Float64}()\n",
    "        for i in I\n",
    "            if weight && !isempty(S[t])\n",
    "                # Weighted average across similar training rows\n",
    "                req_i[i] = mean(df_train[S[t], i])\n",
    "            else\n",
    "                # Fallback: use mean across all train rows\n",
    "                req_i[i] = mean(df_train[:, i])\n",
    "            end\n",
    "        end\n",
    "\n",
    "        # Purchase only what you lack\n",
    "        purchase_i = Dict(i => max(req_i[i] - I0_current[i], 0) for i in I)\n",
    "        I_available = Dict(i => I0_current[i] + purchase_i[i] for i in I)\n",
    "\n",
    "        # --- Solve production optimization ---\n",
    "        model = Model(Gurobi.Optimizer)\n",
    "        set_silent(model)\n",
    "\n",
    "        @variable(model, y[p in P] >= 0, Int)\n",
    "        @variable(model, z[p in P] >= 0, Int)\n",
    "        @variable(model, w[i in I] >= 0)\n",
    "\n",
    "        @objective(model, Max,\n",
    "            sum(π[p] * y[p] for p in P)\n",
    "            - sum(α[p] * z[p] for p in P)\n",
    "            - sum(s[i] * w[i] for i in I)\n",
    "            - sum(10*s[i] * purchase_i[i] for i in I)\n",
    "        )\n",
    "\n",
    "        @constraint(model, [p in P], y[p] + z[p] == d_day[p])\n",
    "        @constraint(model, [i in I], sum(r[(p,i)]*y[p] for p in P) <= I_available[i])\n",
    "        @constraint(model, [i in I], w[i] == I_available[i] - sum(r[(p,i)]*y[p] for p in P))\n",
    "\n",
    "        optimize!(model)\n",
    "\n",
    "        # Extract decisions\n",
    "        y_opt = Dict(p => round(Int, value(y[p])) for p in P)\n",
    "        z_opt = Dict(p => round(Int, value(z[p])) for p in P)\n",
    "        w_opt = Dict(i => value(w[i]) for i in I)\n",
    "\n",
    "        I0_current = deepcopy(w_opt)\n",
    "\n",
    "        daily_profit = objective_value(model)\n",
    "        total_profit += daily_profit\n",
    "\n",
    "        metrics.pizza_produced[t] = sum(values(y_opt))\n",
    "        metrics.unmet_pizza_demand[t] = sum(values(z_opt))\n",
    "        metrics.leftover_ingredients[t] = sum(values(w_opt))\n",
    "        metrics.daily_profit[t] = daily_profit\n",
    "    end\n",
    "\n",
    "    final_spoilage_cost = sum(s[i]*I0_current[i] for i in I)\n",
    "    total_profit_net = total_profit - final_spoilage_cost\n",
    "\n",
    "    return (total_profit = total_profit_net, metrics = metrics)\n",
    "end\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd7c5323",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove ingredient_ prefix from target columns in train_df\n",
    "for col in target_cols\n",
    "    if col in names(train_df)\n",
    "        rename!(train_df, col => Symbol(replace(String(col), \"ingredient_\" => \"\")))\n",
    "    end\n",
    "end\n",
    "\n",
    "pred_result_weighted = run_strategy_weighted(daily_sales_actuals, train_df;\n",
    "                                            S=S, weight=true)\n",
    "\n",
    "println(\"Predictive weighted ORT total profit (net): \", pred_result_weighted.total_profit)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Julia 1.10.10",
   "language": "julia",
   "name": "julia-1.10"
  },
  "language_info": {
   "file_extension": ".jl",
   "mimetype": "application/julia",
   "name": "julia",
   "version": "1.10.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
